# Divider
Gather interesting urls with extensions from a given file.

# What this will do
   This will process files generated by tools like waybackurls,gau,etc containing urls and grab only urls ending with file extensions. 

# Installation
      Clone the repository:
            git clone https://github.com/Aspasht/Divider.git
 
     Install dependencies:
            pip install -r Requirements.txt     


# Available Commands
      $ python divider.py -f myurlfile.txt
      $ python divider.py -f myurlfile.txt -req=True



# Example
    $ cat myUrls.txt
        https://example.com/test/test3
        https://example.com/test.css
        https://example.com/robots.txt
        https://example.com/sitemap.xml
        https://example.com/test?q=testvalue

    $ python divider.py -f myUrls.txt
        https://example.com/robots.txt
        https://example.com/sitemap.xml

# Usage
    usage: divider.py [-h] -f FILE [-req REQUEST]
    options:
      -h, --help                             show this help message and exit
      -f FILE, --file FILE                   Please add target file as argument!
      -req REQUEST, --request REQUEST        Send request for previously generated urls! (Default=False)
      -greq GREQUEST, --grequest GREQUEST    Send request for previously generated urls using grequest! (Default=False)

# Commands
    $ python divider.py -f myurls.txt # Grab urls with extensions without sending any requests.
    $ python divider.py -f myurls.txt -req=True # Send normal requests using httpx module
    $ python divider.py -f myurls.txt -greq=True # Send requests using grequests module
        Note: Use grequests flag if your resulting urls are less in number!
    
